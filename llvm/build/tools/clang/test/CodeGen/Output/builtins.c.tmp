; ModuleID = '/home/jazouani/llvm/llvm-3.2/tools/clang/test/CodeGen/builtins.c'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@.str = private unnamed_addr constant [8 x i8] c"%s: %d\0A\00", align 1
@.str1 = private unnamed_addr constant [8 x i8] c"%s: %f\0A\00", align 1
@.str2 = private unnamed_addr constant [8 x i8] c"%s: %p\0A\00", align 1
@.str3 = private unnamed_addr constant [31 x i8] c"types_compatible_p(int, float)\00", align 1
@.str4 = private unnamed_addr constant [23 x i8] c"choose_expr(0, 10, 20)\00", align 1
@.str5 = private unnamed_addr constant [23 x i8] c"constant_p(sizeof(10))\00", align 1
@.str6 = private unnamed_addr constant [19 x i8] c"expect(N == 12, 0)\00", align 1
@.str7 = private unnamed_addr constant [13 x i8] c"prefetch(&N)\00", align 1
@.str8 = private unnamed_addr constant [16 x i8] c"prefetch(&N, 1)\00", align 1
@.str9 = private unnamed_addr constant [19 x i8] c"prefetch(&N, 1, 0)\00", align 1
@.str10 = private unnamed_addr constant [11 x i8] c"huge_val()\00", align 1
@.str11 = private unnamed_addr constant [12 x i8] c"huge_valf()\00", align 1
@.str12 = private unnamed_addr constant [12 x i8] c"huge_vall()\00", align 1
@.str13 = private unnamed_addr constant [6 x i8] c"inf()\00", align 1
@.str14 = private unnamed_addr constant [7 x i8] c"inff()\00", align 1
@.str15 = private unnamed_addr constant [7 x i8] c"infl()\00", align 1
@.str16 = private unnamed_addr constant [31 x i8] c"fpclassify(0, 1, 2, 3, 4, 1.0)\00", align 1
@.str17 = private unnamed_addr constant [32 x i8] c"fpclassify(0, 1, 2, 3, 4, 1.0f)\00", align 1
@.str18 = private unnamed_addr constant [32 x i8] c"fpclassify(0, 1, 2, 3, 4, 1.0l)\00", align 1
@.str19 = private unnamed_addr constant [8 x i8] c"nan(\22\22)\00", align 1
@.str20 = private unnamed_addr constant [9 x i8] c"nanf(\22\22)\00", align 1
@.str21 = private unnamed_addr constant [9 x i8] c"nanl(\22\22)\00", align 1
@.str22 = private unnamed_addr constant [9 x i8] c"nans(\22\22)\00", align 1
@.str23 = private unnamed_addr constant [10 x i8] c"nan(\2210\22)\00", align 1
@.str24 = private unnamed_addr constant [11 x i8] c"nanf(\2210\22)\00", align 1
@.str25 = private unnamed_addr constant [11 x i8] c"nanl(\2210\22)\00", align 1
@.str26 = private unnamed_addr constant [11 x i8] c"nans(\2210\22)\00", align 1
@.str27 = private unnamed_addr constant [18 x i8] c"isgreater(1., 2.)\00", align 1
@.str28 = private unnamed_addr constant [23 x i8] c"isgreaterequal(1., 2.)\00", align 1
@.str29 = private unnamed_addr constant [15 x i8] c"isless(1., 2.)\00", align 1
@.str30 = private unnamed_addr constant [20 x i8] c"islessequal(1., 2.)\00", align 1
@.str31 = private unnamed_addr constant [22 x i8] c"islessgreater(1., 2.)\00", align 1
@.str32 = private unnamed_addr constant [20 x i8] c"isunordered(1., 2.)\00", align 1
@.str33 = private unnamed_addr constant [10 x i8] c"isnan(1.)\00", align 1
@.str34 = private unnamed_addr constant [7 x i8] c"abs(N)\00", align 1
@.str35 = private unnamed_addr constant [7 x i8] c"clz(N)\00", align 1
@.str36 = private unnamed_addr constant [8 x i8] c"clzl(N)\00", align 1
@.str37 = private unnamed_addr constant [9 x i8] c"clzll(N)\00", align 1
@.str38 = private unnamed_addr constant [7 x i8] c"ctz(N)\00", align 1
@.str39 = private unnamed_addr constant [8 x i8] c"ctzl(N)\00", align 1
@.str40 = private unnamed_addr constant [9 x i8] c"ctzll(N)\00", align 1
@.str41 = private unnamed_addr constant [7 x i8] c"ffs(N)\00", align 1
@.str42 = private unnamed_addr constant [8 x i8] c"ffsl(N)\00", align 1
@.str43 = private unnamed_addr constant [9 x i8] c"ffsll(N)\00", align 1
@.str44 = private unnamed_addr constant [10 x i8] c"parity(N)\00", align 1
@.str45 = private unnamed_addr constant [11 x i8] c"parityl(N)\00", align 1
@.str46 = private unnamed_addr constant [12 x i8] c"parityll(N)\00", align 1
@.str47 = private unnamed_addr constant [12 x i8] c"popcount(N)\00", align 1
@.str48 = private unnamed_addr constant [13 x i8] c"popcountl(N)\00", align 1
@.str49 = private unnamed_addr constant [14 x i8] c"popcountll(N)\00", align 1
@.str50 = private unnamed_addr constant [14 x i8] c"powi(1.2f, N)\00", align 1
@.str51 = private unnamed_addr constant [15 x i8] c"powif(1.2f, N)\00", align 1
@.str52 = private unnamed_addr constant [15 x i8] c"powil(1.2f, N)\00", align 1
@main.s1 = private unnamed_addr constant [6 x i8] c"Hello\00", align 1
@.str53 = private unnamed_addr constant [15 x i8] c"strcat(s0, s1)\00", align 1
@.str54 = private unnamed_addr constant [15 x i8] c"strcmp(s0, s1)\00", align 1
@.str55 = private unnamed_addr constant [19 x i8] c"strncat(s0, s1, n)\00", align 1
@.str56 = private unnamed_addr constant [18 x i8] c"strchr(s0, s1[0])\00", align 1
@.str57 = private unnamed_addr constant [19 x i8] c"strrchr(s0, s1[0])\00", align 1
@.str58 = private unnamed_addr constant [15 x i8] c"strcpy(s0, s1)\00", align 1
@.str59 = private unnamed_addr constant [19 x i8] c"strncpy(s0, s1, n)\00", align 1
@.str60 = private unnamed_addr constant [34 x i8] c"__memset_chk(s0, 0, sizeof s0, n)\00", align 1
@.str61 = private unnamed_addr constant [35 x i8] c"__memcpy_chk(s0, s1, sizeof s0, n)\00", align 1
@.str62 = private unnamed_addr constant [36 x i8] c"__memmove_chk(s0, s1, sizeof s0, n)\00", align 1
@.str63 = private unnamed_addr constant [36 x i8] c"__mempcpy_chk(s0, s1, sizeof s0, n)\00", align 1
@.str64 = private unnamed_addr constant [36 x i8] c"__strncpy_chk(s0, s1, sizeof s0, n)\00", align 1
@.str65 = private unnamed_addr constant [24 x i8] c"__strcpy_chk(s0, s1, n)\00", align 1
@.str66 = private unnamed_addr constant [24 x i8] c"__strcat_chk(s0, s1, n)\00", align 1
@.str67 = private unnamed_addr constant [19 x i8] c"object_size(s0, 0)\00", align 1
@.str68 = private unnamed_addr constant [19 x i8] c"object_size(s0, 1)\00", align 1
@.str69 = private unnamed_addr constant [19 x i8] c"object_size(s0, 2)\00", align 1
@.str70 = private unnamed_addr constant [19 x i8] c"object_size(s0, 3)\00", align 1
@.str71 = private unnamed_addr constant [11 x i8] c"bswap16(N)\00", align 1
@.str72 = private unnamed_addr constant [11 x i8] c"bswap32(N)\00", align 1
@.str73 = private unnamed_addr constant [11 x i8] c"bswap64(N)\00", align 1
@.str74 = private unnamed_addr constant [7 x i8] c"trap()\00", align 1
@.str75 = private unnamed_addr constant [24 x i8] c"extract_return_addr(&N)\00", align 1
@.str76 = private unnamed_addr constant [13 x i8] c"signbit(1.0)\00", align 1

define void @p(i8* %str, i32 %x) nounwind {
entry:
  %str.addr = alloca i8*, align 8
  %x.addr = alloca i32, align 4
  store i8* %str, i8** %str.addr, align 8
  store i32 %x, i32* %x.addr, align 4
  %0 = load i8** %str.addr, align 8
  %1 = load i32* %x.addr, align 4
  %call = call i32 (i8*, ...)* @printf(i8* getelementptr inbounds ([8 x i8]* @.str, i32 0, i32 0), i8* %0, i32 %1)
  ret void
}

declare i32 @printf(i8*, ...)

define void @q(i8* %str, double %x) nounwind {
entry:
  %str.addr = alloca i8*, align 8
  %x.addr = alloca double, align 8
  store i8* %str, i8** %str.addr, align 8
  store double %x, double* %x.addr, align 8
  %0 = load i8** %str.addr, align 8
  %1 = load double* %x.addr, align 8
  %call = call i32 (i8*, ...)* @printf(i8* getelementptr inbounds ([8 x i8]* @.str1, i32 0, i32 0), i8* %0, double %1)
  ret void
}

define void @r(i8* %str, i8* %ptr) nounwind {
entry:
  %str.addr = alloca i8*, align 8
  %ptr.addr = alloca i8*, align 8
  store i8* %str, i8** %str.addr, align 8
  store i8* %ptr, i8** %ptr.addr, align 8
  %0 = load i8** %str.addr, align 8
  %1 = load i8** %ptr.addr, align 8
  %call = call i32 (i8*, ...)* @printf(i8* getelementptr inbounds ([8 x i8]* @.str2, i32 0, i32 0), i8* %0, i8* %1)
  ret void
}

define i32 @main() nounwind {
entry:
  %retval = alloca i32, align 4
  %N = alloca i32, align 4
  %a = alloca i32, align 4
  %b = alloca i32, align 4
  %n = alloca i32, align 4
  %s0 = alloca [10 x i8], align 1
  %s1 = alloca [6 x i8], align 1
  store i32 0, i32* %retval
  %call = call i32 @random()
  store i32 %call, i32* %N, align 4
  call void @p(i8* getelementptr inbounds ([31 x i8]* @.str3, i32 0, i32 0), i32 0)
  call void @p(i8* getelementptr inbounds ([23 x i8]* @.str4, i32 0, i32 0), i32 20)
  call void @p(i8* getelementptr inbounds ([23 x i8]* @.str5, i32 0, i32 0), i32 1)
  %0 = load i32* %N, align 4
  %cmp = icmp eq i32 %0, 12
  %conv = zext i1 %cmp to i32
  %conv1 = sext i32 %conv to i64
  %expval = call i64 @llvm.expect.i64(i64 %conv1, i64 0)
  %conv2 = trunc i64 %expval to i32
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str6, i32 0, i32 0), i32 %conv2)
  %1 = bitcast i32* %N to i8*
  call void @llvm.prefetch(i8* %1, i32 0, i32 3, i32 1)
  call void @p(i8* getelementptr inbounds ([13 x i8]* @.str7, i32 0, i32 0), i32 0)
  %2 = bitcast i32* %N to i8*
  call void @llvm.prefetch(i8* %2, i32 1, i32 3, i32 1)
  call void @p(i8* getelementptr inbounds ([16 x i8]* @.str8, i32 0, i32 0), i32 0)
  %3 = bitcast i32* %N to i8*
  call void @llvm.prefetch(i8* %3, i32 1, i32 0, i32 1)
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str9, i32 0, i32 0), i32 0)
  call void @q(i8* getelementptr inbounds ([11 x i8]* @.str10, i32 0, i32 0), double 0x7FF0000000000000)
  call void @q(i8* getelementptr inbounds ([12 x i8]* @.str11, i32 0, i32 0), double 0x7FF0000000000000)
  call void @q(i8* getelementptr inbounds ([12 x i8]* @.str12, i32 0, i32 0), double 0x7FF0000000000000)
  call void @q(i8* getelementptr inbounds ([6 x i8]* @.str13, i32 0, i32 0), double 0x7FF0000000000000)
  call void @q(i8* getelementptr inbounds ([7 x i8]* @.str14, i32 0, i32 0), double 0x7FF0000000000000)
  call void @q(i8* getelementptr inbounds ([7 x i8]* @.str15, i32 0, i32 0), double 0x7FF0000000000000)
  br i1 false, label %fpclassify_end, label %fpclassify_not_zero

fpclassify_end:                                   ; preds = %fpclassify_not_inf, %fpclassify_not_nan, %fpclassify_not_zero, %entry
  %fpclassify_result = phi i32 [ 4, %entry ], [ 0, %fpclassify_not_zero ], [ 1, %fpclassify_not_nan ], [ %4, %fpclassify_not_inf ]
  call void @p(i8* getelementptr inbounds ([31 x i8]* @.str16, i32 0, i32 0), i32 %fpclassify_result)
  br i1 false, label %fpclassify_end3, label %fpclassify_not_zero5

fpclassify_not_zero:                              ; preds = %entry
  br i1 false, label %fpclassify_end, label %fpclassify_not_nan

fpclassify_not_nan:                               ; preds = %fpclassify_not_zero
  %abs = call double @fabs(double 1.000000e+00)
  %isinf = fcmp oeq double %abs, 0x7FF0000000000000
  br i1 %isinf, label %fpclassify_end, label %fpclassify_not_inf

fpclassify_not_inf:                               ; preds = %fpclassify_not_nan
  %isnormal = fcmp uge double %abs, 0x10000000000000
  %4 = select i1 %isnormal, i32 2, i32 3
  br label %fpclassify_end

fpclassify_end3:                                  ; preds = %fpclassify_not_inf9, %fpclassify_not_nan6, %fpclassify_not_zero5, %fpclassify_end
  %fpclassify_result4 = phi i32 [ 4, %fpclassify_end ], [ 0, %fpclassify_not_zero5 ], [ 1, %fpclassify_not_nan6 ], [ %5, %fpclassify_not_inf9 ]
  call void @p(i8* getelementptr inbounds ([32 x i8]* @.str17, i32 0, i32 0), i32 %fpclassify_result4)
  br i1 false, label %fpclassify_end11, label %fpclassify_not_zero13

fpclassify_not_zero5:                             ; preds = %fpclassify_end
  br i1 false, label %fpclassify_end3, label %fpclassify_not_nan6

fpclassify_not_nan6:                              ; preds = %fpclassify_not_zero5
  %abs7 = call float @fabsf(float 1.000000e+00)
  %isinf8 = fcmp oeq float %abs7, 0x7FF0000000000000
  br i1 %isinf8, label %fpclassify_end3, label %fpclassify_not_inf9

fpclassify_not_inf9:                              ; preds = %fpclassify_not_nan6
  %isnormal10 = fcmp uge float %abs7, 0x3810000000000000
  %5 = select i1 %isnormal10, i32 2, i32 3
  br label %fpclassify_end3

fpclassify_end11:                                 ; preds = %fpclassify_not_inf17, %fpclassify_not_nan14, %fpclassify_not_zero13, %fpclassify_end3
  %fpclassify_result12 = phi i32 [ 4, %fpclassify_end3 ], [ 0, %fpclassify_not_zero13 ], [ 1, %fpclassify_not_nan14 ], [ %68, %fpclassify_not_inf17 ]
  call void @p(i8* getelementptr inbounds ([32 x i8]* @.str18, i32 0, i32 0), i32 %fpclassify_result12)
  call void @q(i8* getelementptr inbounds ([8 x i8]* @.str19, i32 0, i32 0), double 0x7FF8000000000000)
  call void @q(i8* getelementptr inbounds ([9 x i8]* @.str20, i32 0, i32 0), double 0x7FF8000000000000)
  call void @q(i8* getelementptr inbounds ([9 x i8]* @.str21, i32 0, i32 0), double 0x7FF8000000000000)
  call void @q(i8* getelementptr inbounds ([9 x i8]* @.str22, i32 0, i32 0), double 0x7FF4000000000000)
  call void @q(i8* getelementptr inbounds ([10 x i8]* @.str23, i32 0, i32 0), double 0x7FF800000000000A)
  call void @q(i8* getelementptr inbounds ([11 x i8]* @.str24, i32 0, i32 0), double 0x7FF8000140000000)
  call void @q(i8* getelementptr inbounds ([11 x i8]* @.str25, i32 0, i32 0), double 0x7FF8000000000000)
  call void @q(i8* getelementptr inbounds ([11 x i8]* @.str26, i32 0, i32 0), double 0x7FF000000000000A)
  call void @p(i8* getelementptr inbounds ([18 x i8]* @.str27, i32 0, i32 0), i32 0)
  call void @p(i8* getelementptr inbounds ([23 x i8]* @.str28, i32 0, i32 0), i32 0)
  call void @p(i8* getelementptr inbounds ([15 x i8]* @.str29, i32 0, i32 0), i32 1)
  call void @p(i8* getelementptr inbounds ([20 x i8]* @.str30, i32 0, i32 0), i32 1)
  call void @p(i8* getelementptr inbounds ([22 x i8]* @.str31, i32 0, i32 0), i32 1)
  call void @p(i8* getelementptr inbounds ([20 x i8]* @.str32, i32 0, i32 0), i32 0)
  call void @p(i8* getelementptr inbounds ([10 x i8]* @.str33, i32 0, i32 0), i32 0)
  %6 = load i32* %N, align 4
  %neg = sub i32 0, %6
  %abscond = icmp sge i32 %6, 0
  %abs19 = select i1 %abscond, i32 %6, i32 %neg
  call void @p(i8* getelementptr inbounds ([7 x i8]* @.str34, i32 0, i32 0), i32 %abs19)
  %7 = load i32* %N, align 4
  %8 = call i32 @llvm.ctlz.i32(i32 %7, i1 true)
  call void @p(i8* getelementptr inbounds ([7 x i8]* @.str35, i32 0, i32 0), i32 %8)
  %9 = load i32* %N, align 4
  %conv20 = sext i32 %9 to i64
  %10 = call i64 @llvm.ctlz.i64(i64 %conv20, i1 true)
  %cast = trunc i64 %10 to i32
  call void @p(i8* getelementptr inbounds ([8 x i8]* @.str36, i32 0, i32 0), i32 %cast)
  %11 = load i32* %N, align 4
  %conv21 = sext i32 %11 to i64
  %12 = call i64 @llvm.ctlz.i64(i64 %conv21, i1 true)
  %cast22 = trunc i64 %12 to i32
  call void @p(i8* getelementptr inbounds ([9 x i8]* @.str37, i32 0, i32 0), i32 %cast22)
  %13 = load i32* %N, align 4
  %14 = call i32 @llvm.cttz.i32(i32 %13, i1 true)
  call void @p(i8* getelementptr inbounds ([7 x i8]* @.str38, i32 0, i32 0), i32 %14)
  %15 = load i32* %N, align 4
  %conv23 = sext i32 %15 to i64
  %16 = call i64 @llvm.cttz.i64(i64 %conv23, i1 true)
  %cast24 = trunc i64 %16 to i32
  call void @p(i8* getelementptr inbounds ([8 x i8]* @.str39, i32 0, i32 0), i32 %cast24)
  %17 = load i32* %N, align 4
  %conv25 = sext i32 %17 to i64
  %18 = call i64 @llvm.cttz.i64(i64 %conv25, i1 true)
  %cast26 = trunc i64 %18 to i32
  call void @p(i8* getelementptr inbounds ([9 x i8]* @.str40, i32 0, i32 0), i32 %cast26)
  %19 = load i32* %N, align 4
  %20 = call i32 @llvm.cttz.i32(i32 %19, i1 true)
  %21 = add i32 %20, 1
  %iszero = icmp eq i32 %19, 0
  %ffs = select i1 %iszero, i32 0, i32 %21
  call void @p(i8* getelementptr inbounds ([7 x i8]* @.str41, i32 0, i32 0), i32 %ffs)
  %22 = load i32* %N, align 4
  %conv27 = sext i32 %22 to i64
  %23 = call i64 @llvm.cttz.i64(i64 %conv27, i1 true)
  %24 = add i64 %23, 1
  %iszero28 = icmp eq i64 %conv27, 0
  %ffs29 = select i1 %iszero28, i64 0, i64 %24
  %cast30 = trunc i64 %ffs29 to i32
  call void @p(i8* getelementptr inbounds ([8 x i8]* @.str42, i32 0, i32 0), i32 %cast30)
  %25 = load i32* %N, align 4
  %conv31 = sext i32 %25 to i64
  %26 = call i64 @llvm.cttz.i64(i64 %conv31, i1 true)
  %27 = add i64 %26, 1
  %iszero32 = icmp eq i64 %conv31, 0
  %ffs33 = select i1 %iszero32, i64 0, i64 %27
  %cast34 = trunc i64 %ffs33 to i32
  call void @p(i8* getelementptr inbounds ([9 x i8]* @.str43, i32 0, i32 0), i32 %cast34)
  %28 = load i32* %N, align 4
  %29 = call i32 @llvm.ctpop.i32(i32 %28)
  %30 = and i32 %29, 1
  call void @p(i8* getelementptr inbounds ([10 x i8]* @.str44, i32 0, i32 0), i32 %30)
  %31 = load i32* %N, align 4
  %conv35 = sext i32 %31 to i64
  %32 = call i64 @llvm.ctpop.i64(i64 %conv35)
  %33 = and i64 %32, 1
  %cast36 = trunc i64 %33 to i32
  call void @p(i8* getelementptr inbounds ([11 x i8]* @.str45, i32 0, i32 0), i32 %cast36)
  %34 = load i32* %N, align 4
  %conv37 = sext i32 %34 to i64
  %35 = call i64 @llvm.ctpop.i64(i64 %conv37)
  %36 = and i64 %35, 1
  %cast38 = trunc i64 %36 to i32
  call void @p(i8* getelementptr inbounds ([12 x i8]* @.str46, i32 0, i32 0), i32 %cast38)
  %37 = load i32* %N, align 4
  %38 = call i32 @llvm.ctpop.i32(i32 %37)
  call void @p(i8* getelementptr inbounds ([12 x i8]* @.str47, i32 0, i32 0), i32 %38)
  %39 = load i32* %N, align 4
  %conv39 = sext i32 %39 to i64
  %40 = call i64 @llvm.ctpop.i64(i64 %conv39)
  %cast40 = trunc i64 %40 to i32
  call void @p(i8* getelementptr inbounds ([13 x i8]* @.str48, i32 0, i32 0), i32 %cast40)
  %41 = load i32* %N, align 4
  %conv41 = sext i32 %41 to i64
  %42 = call i64 @llvm.ctpop.i64(i64 %conv41)
  %cast42 = trunc i64 %42 to i32
  call void @p(i8* getelementptr inbounds ([14 x i8]* @.str49, i32 0, i32 0), i32 %cast42)
  %43 = load i32* %N, align 4
  %44 = call double @llvm.powi.f64(double 0x3FF3333340000000, i32 %43)
  call void @q(i8* getelementptr inbounds ([14 x i8]* @.str50, i32 0, i32 0), double %44)
  %45 = load i32* %N, align 4
  %46 = call float @llvm.powi.f32(float 0x3FF3333340000000, i32 %45)
  %conv43 = fpext float %46 to double
  call void @q(i8* getelementptr inbounds ([15 x i8]* @.str51, i32 0, i32 0), double %conv43)
  %47 = load i32* %N, align 4
  %48 = call x86_fp80 @llvm.powi.f80(x86_fp80 0xK3FFF99999A0000000000, i32 %47)
  %conv44 = fptrunc x86_fp80 %48 to double
  call void @q(i8* getelementptr inbounds ([15 x i8]* @.str52, i32 0, i32 0), double %conv44)
  %call45 = call i32 @random()
  store i32 %call45, i32* %n, align 4
  %49 = bitcast [6 x i8]* %s1 to i8*
  call void @llvm.memcpy.p0i8.p0i8.i64(i8* %49, i8* getelementptr inbounds ([6 x i8]* @main.s1, i32 0, i32 0), i64 6, i32 1, i1 false)
  %arraydecay = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay46 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %call47 = call i8* @strcat(i8* %arraydecay, i8* %arraydecay46) nounwind
  call void @p(i8* getelementptr inbounds ([15 x i8]* @.str53, i32 0, i32 0), i32 0)
  %arraydecay48 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay49 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %call50 = call i32 @strcmp(i8* %arraydecay48, i8* %arraydecay49) nounwind
  call void @p(i8* getelementptr inbounds ([15 x i8]* @.str54, i32 0, i32 0), i32 0)
  %arraydecay51 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay52 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %50 = load i32* %n, align 4
  %conv53 = sext i32 %50 to i64
  %call54 = call i8* @strncat(i8* %arraydecay51, i8* %arraydecay52, i64 %conv53) nounwind
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str55, i32 0, i32 0), i32 0)
  %arraydecay55 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arrayidx = getelementptr inbounds [6 x i8]* %s1, i32 0, i64 0
  %51 = load i8* %arrayidx, align 1
  %conv56 = sext i8 %51 to i32
  %call57 = call i8* @strchr(i8* %arraydecay55, i32 %conv56) nounwind
  call void @p(i8* getelementptr inbounds ([18 x i8]* @.str56, i32 0, i32 0), i32 0)
  %arraydecay58 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arrayidx59 = getelementptr inbounds [6 x i8]* %s1, i32 0, i64 0
  %52 = load i8* %arrayidx59, align 1
  %conv60 = sext i8 %52 to i32
  %call61 = call i8* @strrchr(i8* %arraydecay58, i32 %conv60) nounwind
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str57, i32 0, i32 0), i32 0)
  %arraydecay62 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay63 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %call64 = call i8* @strcpy(i8* %arraydecay62, i8* %arraydecay63) nounwind
  call void @p(i8* getelementptr inbounds ([15 x i8]* @.str58, i32 0, i32 0), i32 0)
  %arraydecay65 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay66 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %53 = load i32* %n, align 4
  %conv67 = sext i32 %53 to i64
  %call68 = call i8* @strncpy(i8* %arraydecay65, i8* %arraydecay66, i64 %conv67) nounwind
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str59, i32 0, i32 0), i32 0)
  %arraydecay69 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %54 = load i32* %n, align 4
  %conv70 = sext i32 %54 to i64
  %call71 = call i8* @__memset_chk(i8* %arraydecay69, i32 0, i64 10, i64 %conv70) nounwind
  call void @p(i8* getelementptr inbounds ([34 x i8]* @.str60, i32 0, i32 0), i32 0)
  %arraydecay72 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay73 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %55 = load i32* %n, align 4
  %conv74 = sext i32 %55 to i64
  %call75 = call i8* @__memcpy_chk(i8* %arraydecay72, i8* %arraydecay73, i64 10, i64 %conv74) nounwind
  call void @p(i8* getelementptr inbounds ([35 x i8]* @.str61, i32 0, i32 0), i32 0)
  %arraydecay76 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay77 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %56 = load i32* %n, align 4
  %conv78 = sext i32 %56 to i64
  %call79 = call i8* @__memmove_chk(i8* %arraydecay76, i8* %arraydecay77, i64 10, i64 %conv78) nounwind
  call void @p(i8* getelementptr inbounds ([36 x i8]* @.str62, i32 0, i32 0), i32 0)
  %arraydecay80 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay81 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %57 = load i32* %n, align 4
  %conv82 = sext i32 %57 to i64
  %call83 = call i8* @__mempcpy_chk(i8* %arraydecay80, i8* %arraydecay81, i64 10, i64 %conv82) nounwind
  call void @p(i8* getelementptr inbounds ([36 x i8]* @.str63, i32 0, i32 0), i32 0)
  %arraydecay84 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay85 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %58 = load i32* %n, align 4
  %conv86 = sext i32 %58 to i64
  %call87 = call i8* @__strncpy_chk(i8* %arraydecay84, i8* %arraydecay85, i64 10, i64 %conv86) nounwind
  call void @p(i8* getelementptr inbounds ([36 x i8]* @.str64, i32 0, i32 0), i32 0)
  %arraydecay88 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay89 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %59 = load i32* %n, align 4
  %conv90 = sext i32 %59 to i64
  %call91 = call i8* @__strcpy_chk(i8* %arraydecay88, i8* %arraydecay89, i64 %conv90) nounwind
  call void @p(i8* getelementptr inbounds ([24 x i8]* @.str65, i32 0, i32 0), i32 0)
  %arrayidx92 = getelementptr inbounds [10 x i8]* %s0, i32 0, i64 0
  store i8 0, i8* %arrayidx92, align 1
  %arraydecay93 = getelementptr inbounds [10 x i8]* %s0, i32 0, i32 0
  %arraydecay94 = getelementptr inbounds [6 x i8]* %s1, i32 0, i32 0
  %60 = load i32* %n, align 4
  %conv95 = sext i32 %60 to i64
  %call96 = call i8* @__strcat_chk(i8* %arraydecay93, i8* %arraydecay94, i64 %conv95) nounwind
  call void @p(i8* getelementptr inbounds ([24 x i8]* @.str66, i32 0, i32 0), i32 0)
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str67, i32 0, i32 0), i32 10)
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str68, i32 0, i32 0), i32 10)
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str69, i32 0, i32 0), i32 10)
  call void @p(i8* getelementptr inbounds ([19 x i8]* @.str70, i32 0, i32 0), i32 10)
  %61 = load i32* %N, align 4
  %conv97 = trunc i32 %61 to i16
  %62 = call i16 @llvm.bswap.i16(i16 %conv97)
  %conv98 = zext i16 %62 to i32
  call void @p(i8* getelementptr inbounds ([11 x i8]* @.str71, i32 0, i32 0), i32 %conv98)
  %63 = load i32* %N, align 4
  %64 = call i32 @llvm.bswap.i32(i32 %63)
  call void @p(i8* getelementptr inbounds ([11 x i8]* @.str72, i32 0, i32 0), i32 %64)
  %65 = load i32* %N, align 4
  %conv99 = sext i32 %65 to i64
  %66 = call i64 @llvm.bswap.i64(i64 %conv99)
  %conv100 = trunc i64 %66 to i32
  call void @p(i8* getelementptr inbounds ([11 x i8]* @.str73, i32 0, i32 0), i32 %conv100)
  call void @llvm.trap()
  call void @p(i8* getelementptr inbounds ([7 x i8]* @.str74, i32 0, i32 0), i32 0)
  %67 = bitcast i32* %N to i8*
  call void @r(i8* getelementptr inbounds ([24 x i8]* @.str75, i32 0, i32 0), i8* %67)
  call void @p(i8* getelementptr inbounds ([13 x i8]* @.str76, i32 0, i32 0), i32 0)
  ret i32 0

fpclassify_not_zero13:                            ; preds = %fpclassify_end3
  br i1 false, label %fpclassify_end11, label %fpclassify_not_nan14

fpclassify_not_nan14:                             ; preds = %fpclassify_not_zero13
  %abs15 = call x86_fp80 @fabsl(x86_fp80 0xK3FFF8000000000000000)
  %isinf16 = fcmp oeq x86_fp80 %abs15, 0xK7FFF8000000000000000
  br i1 %isinf16, label %fpclassify_end11, label %fpclassify_not_inf17

fpclassify_not_inf17:                             ; preds = %fpclassify_not_nan14
  %isnormal18 = fcmp uge x86_fp80 %abs15, 0xK00018000000000000000
  %68 = select i1 %isnormal18, i32 2, i32 3
  br label %fpclassify_end11
}

declare i32 @random()

declare i64 @llvm.expect.i64(i64, i64) nounwind readnone

declare void @llvm.prefetch(i8* nocapture, i32, i32, i32) nounwind

declare double @fabs(double)

declare float @fabsf(float)

declare x86_fp80 @fabsl(x86_fp80)

declare i32 @llvm.ctlz.i32(i32, i1) nounwind readnone

declare i64 @llvm.ctlz.i64(i64, i1) nounwind readnone

declare i32 @llvm.cttz.i32(i32, i1) nounwind readnone

declare i64 @llvm.cttz.i64(i64, i1) nounwind readnone

declare i32 @llvm.ctpop.i32(i32) nounwind readnone

declare i64 @llvm.ctpop.i64(i64) nounwind readnone

declare double @llvm.powi.f64(double, i32) nounwind readonly

declare float @llvm.powi.f32(float, i32) nounwind readonly

declare x86_fp80 @llvm.powi.f80(x86_fp80, i32) nounwind readonly

declare void @llvm.memcpy.p0i8.p0i8.i64(i8* nocapture, i8* nocapture, i64, i32, i1) nounwind

declare i8* @strcat(i8*, i8*) nounwind

declare i32 @strcmp(i8*, i8*) nounwind

declare i8* @strncat(i8*, i8*, i64) nounwind

declare i8* @strchr(i8*, i32) nounwind

declare i8* @strrchr(i8*, i32) nounwind

declare i8* @strcpy(i8*, i8*) nounwind

declare i8* @strncpy(i8*, i8*, i64) nounwind

declare i8* @__memset_chk(i8*, i32, i64, i64) nounwind

declare i8* @__memcpy_chk(i8*, i8*, i64, i64) nounwind

declare i8* @__memmove_chk(i8*, i8*, i64, i64) nounwind

declare i8* @__mempcpy_chk(i8*, i8*, i64, i64) nounwind

declare i8* @__strncpy_chk(i8*, i8*, i64, i64) nounwind

declare i8* @__strcpy_chk(i8*, i8*, i64) nounwind

declare i8* @__strcat_chk(i8*, i8*, i64) nounwind

declare i16 @llvm.bswap.i16(i16) nounwind readnone

declare i32 @llvm.bswap.i32(i32) nounwind readnone

declare i64 @llvm.bswap.i64(i64) nounwind readnone

declare void @llvm.trap() noreturn nounwind

define void @foo() nounwind {
entry:
  %call = call i8* @strcat(i8* null, i8* null) nounwind
  ret void
}

define void @bar() nounwind {
entry:
  %f = alloca float, align 4
  %d = alloca double, align 8
  %ld = alloca x86_fp80, align 16
  store float 0x7FF0000000000000, float* %f, align 4
  store double 0x7FF0000000000000, double* %d, align 8
  store x86_fp80 0xK7FFF8000000000000000, x86_fp80* %ld, align 16
  store float 0x7FF8000000000000, float* %f, align 4
  store double 0x7FF8000000000000, double* %d, align 8
  store x86_fp80 0xK7FFFC000000000000000, x86_fp80* %ld, align 16
  store float 0x7FF815D300000000, float* %f, align 4
  store double 0x7FF800000000AE98, double* %d, align 8
  store x86_fp80 0xK7FFFC00000000000AE98, x86_fp80* %ld, align 16
  store float 0x7FF4000000000000, float* %f, align 4
  store double 0x7FF4000000000000, double* %d, align 8
  store x86_fp80 0xK7FFFA000000000000000, x86_fp80* %ld, align 16
  store float 0x7FF015D300000000, float* %f, align 4
  store double 0x7FF000000000AE98, double* %d, align 8
  store x86_fp80 0xK7FFF800000000000AE98, x86_fp80* %ld, align 16
  ret void
}

define void @test_float_builtins(float %F, double %D, x86_fp80 %LD) nounwind {
entry:
  %F.addr = alloca float, align 4
  %D.addr = alloca double, align 8
  %LD.addr = alloca x86_fp80, align 16
  %res = alloca i32, align 4
  store float %F, float* %F.addr, align 4
  store double %D, double* %D.addr, align 8
  store x86_fp80 %LD, x86_fp80* %LD.addr, align 16
  %0 = load float* %F.addr, align 4
  %abs = call float @fabsf(float %0)
  %isinf = fcmp oeq float %abs, 0x7FF0000000000000
  %1 = zext i1 %isinf to i32
  store volatile i32 %1, i32* %res, align 4
  %2 = load double* %D.addr, align 8
  %abs1 = call double @fabs(double %2)
  %isinf2 = fcmp oeq double %abs1, 0x7FF0000000000000
  %3 = zext i1 %isinf2 to i32
  store volatile i32 %3, i32* %res, align 4
  %4 = load x86_fp80* %LD.addr, align 16
  %abs3 = call x86_fp80 @fabsl(x86_fp80 %4)
  %isinf4 = fcmp oeq x86_fp80 %abs3, 0xK7FFF8000000000000000
  %5 = zext i1 %isinf4 to i32
  store volatile i32 %5, i32* %res, align 4
  %6 = load float* %F.addr, align 4
  %iseq = fcmp oeq float %6, %6
  %abs5 = call float @fabsf(float %6)
  %isinf6 = fcmp une float %abs5, 0x7FF0000000000000
  %and = and i1 %iseq, %isinf6
  %7 = zext i1 %and to i32
  store volatile i32 %7, i32* %res, align 4
  %8 = load float* %F.addr, align 4
  %iseq7 = fcmp oeq float %8, %8
  %abs8 = call float @fabsf(float %8)
  %isinf9 = fcmp ult float %abs8, 0x7FF0000000000000
  %isnormal = fcmp uge float %abs8, 0x3810000000000000
  %and10 = and i1 %iseq7, %isinf9
  %and11 = and i1 %and10, %isnormal
  %9 = zext i1 %and11 to i32
  store volatile i32 %9, i32* %res, align 4
  ret void
}

define void @test_builtin_longjmp(i8** %buffer) nounwind {
entry:
  %buffer.addr = alloca i8**, align 8
  store i8** %buffer, i8*** %buffer.addr, align 8
  %0 = load i8*** %buffer.addr, align 8
  %1 = bitcast i8** %0 to i8*
  call void @llvm.eh.sjlj.longjmp(i8* %1)
  unreachable

return:                                           ; No predecessors!
  ret void
}

declare void @llvm.eh.sjlj.longjmp(i8*) noreturn nounwind

define i64 @test_builtin_readcyclecounter() nounwind {
entry:
  %0 = call i64 @llvm.readcyclecounter()
  ret i64 %0
}

declare i64 @llvm.readcyclecounter() nounwind
